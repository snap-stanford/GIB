{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:57.810265Z",
     "start_time": "2022-07-30T23:07:57.422321Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:58.452112Z",
     "start_time": "2022-07-30T23:07:57.811623Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.data import get_data\n",
    "\n",
    "dataset = get_data(\"Cora\") # no attack get_data(\"Cora\", \"n:10\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:58.546643Z",
     "start_time": "2022-07-30T23:07:58.453388Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models.gat import GIBGAT\n",
    "from models.gcn import GIBGCN\n",
    "\n",
    "from modules.train import train_node_level\n",
    "\n",
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(\"Train accuracy: %4.2f%%\" % (100.0 * result_dict[\"train\"]))\n",
    "    if \"val\" in result_dict:\n",
    "        print(\"Val accuracy:   %4.2f%%\" % (100.0 * result_dict[\"val\"]))\n",
    "    print(\"Test accuracy:  %4.2f%%\" % (100.0 * result_dict[\"test\"]))\n",
    "    \n",
    "class Config(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:58.556231Z",
     "start_time": "2022-07-30T23:07:58.548170Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'GGCN_CORA',\n",
       " 'model': GIBGCN(\n",
       "   (conv1): GCNConv(1433, 8)\n",
       "   (conv2): GCNConv(8, 7)\n",
       " ),\n",
       " 'model_name': 'GIB-GCN',\n",
       " 'dataset_name': 'Cora',\n",
       " 'lr': 0.03,\n",
       " 'weight_decay': 0.0005,\n",
       " 'beta1': 0.001,\n",
       " 'beta2': 0.01,\n",
       " 'CHECKPOINT_PATH': '../saved_models',\n",
       " 'device': device(type='cuda'),\n",
       " 'loss_type': 'softmax'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_GIBGCN = Config(\n",
    "    exp_name=\"GGCN_CORA\",\n",
    "    model=GIBGCN(dataset.num_features, dataset.num_classes, latent_size=8),\n",
    "    model_name=\"GIB-GCN\",\n",
    "    dataset_name=\"Cora\",\n",
    "    lr=0.03,\n",
    "    weight_decay=5e-4,\n",
    "    beta1=0.001,\n",
    "    beta2=0.01,\n",
    "    CHECKPOINT_PATH=\"../saved_models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_type=dataset.loss,\n",
    ")\n",
    "conf_GIBGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:58.558876Z",
     "start_time": "2022-07-30T23:07:58.557287Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pl_GIBGCN, result_GIBGCN = train_node_level(\n",
    "#     conf_GIBGCN,\n",
    "#     dataset,\n",
    "# )\n",
    "\n",
    "# print_results(result_GIBGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:07:58.568492Z",
     "start_time": "2022-07-30T23:07:58.559959Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'GIBGAT_CORA',\n",
       " 'model': GIBGAT(\n",
       "   (conv1): GATConv(1433, 8, heads=1)\n",
       "   (conv2): GATConv(8, 7, heads=1)\n",
       " ),\n",
       " 'model_name': 'GIB-GAT',\n",
       " 'struct_dropout_mode': ('standard', 0.6),\n",
       " 'dataset_name': 'Cora',\n",
       " 'lr': 0.03,\n",
       " 'weight_decay': 0.0005,\n",
       " 'beta1': 0.001,\n",
       " 'beta2': 0.01,\n",
       " 'CHECKPOINT_PATH': '../saved_models',\n",
       " 'device': device(type='cuda'),\n",
       " 'loss_type': 'softmax'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_GIBGAT = Config(\n",
    "    exp_name=\"GIBGAT_CORA\",\n",
    "    model=GIBGAT(dataset.num_features, dataset.num_classes, latent_size=8),\n",
    "    model_name=\"GIB-GAT\",\n",
    "    struct_dropout_mode=(\"standard\", 0.6), # struct_dropout_mode = (\"DNsampling\",'multi-categorical-sum',1,3,2) GIB CAT\n",
    "    dataset_name=\"Cora\",\n",
    "    lr=0.03,\n",
    "    weight_decay=5e-4,\n",
    "    beta1=0.001,\n",
    "    beta2=0.01,\n",
    "    CHECKPOINT_PATH=\"../saved_models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_type=dataset.loss,\n",
    ")\n",
    "conf_GIBGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:08:29.867295Z",
     "start_time": "2022-07-30T23:07:58.569480Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data/home/Personal/UCH/2022-sem1/proyecto-graph-ib/GIB/experiments/wandb/run-20220730_190804-xmkcw0jx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/stepp1/gib/runs/xmkcw0jx\" target=\"_blank\">GIBGAT_CORA</a></strong> to <a href=\"https://wandb.ai/stepp1/gib\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/.miniconda3/envs/gib/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | GIBGAT | 11.6 K\n",
      "---------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/.miniconda3/envs/gib/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/step/.miniconda3/envs/gib/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8226fa5dd4d84c71bb9b5ac66a23858c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caef67475e74c14a3bbe1a8e5331a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 8]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "torch.Size([2708, 7]) torch.Size([2708, 4, 1]) torch.Size([2708, 4, 1])\n",
      "Train accuracy: 27.86%\n",
      "Val accuracy:   26.40%\n",
      "Test accuracy:  52.50%\n"
     ]
    }
   ],
   "source": [
    "pl_GIBGAT, result_GIBGAT = train_node_level(\n",
    "    conf_GIBGAT,\n",
    "    dataset,\n",
    ")\n",
    "\n",
    "print_results(result_GIBGAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T23:08:29.872434Z",
     "start_time": "2022-07-30T23:08:29.868641Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2113321578.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_767870/2113321578.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    dataset_name=\"Cora\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conf_GIBGAT = Config(\n",
    "    exp_name=\"GIBGAT_CORA-DNsampling\",\n",
    "    model=GIBGAT(dataset.num_features, dataset.num_classes, latent_size=8, struct_dropout_mode = (\"DNsampling\",'multi-categorical-sum',1,3,2)),\n",
    "    model_name=\"GIB-GAT-DNsampling\",\n",
    "    struct_dropout_mode = (\"DNsampling\",'multi-categorical-sum',1,3,2)\n",
    "    dataset_name=\"Cora\",\n",
    "    lr=0.03,\n",
    "    weight_decay=5e-4,\n",
    "    beta1=0.001,\n",
    "    beta2=0.01,\n",
    "    CHECKPOINT_PATH=\"../saved_models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_type=dataset.loss,\n",
    ")\n",
    "conf_GIBGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gib]",
   "language": "python",
   "name": "conda-env-gib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77c1299cf2bba9865bef8f8ed634cd10cb53d9d1f8df6a2f93c559b128ca495a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
